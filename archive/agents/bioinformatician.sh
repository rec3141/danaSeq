#!/usr/bin/env bash
################################################################################
#                                                                              #
#  ðŸ’»  AGENT: THE BIOINFORMATICIAN  ðŸ’»                                         #
#                                                                              #
#  "Pipelines are poetry. Let me optimize yours."                             #
#                                                                              #
################################################################################

readonly GREEN='\033[0;32m'
readonly YELLOW='\033[1;33m'
readonly BOLD='\033[1m'
readonly NC='\033[0m'

cat << "EOF"

     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚  ðŸ’»   THE BIOINFORMATICIAN SPEAKS   ðŸ’»        â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

     "I've wrangled a petabyte of sequencing data and
      lived to tell the tale. Let me save you from my
      mistakes."

     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

EOF

echo -e "${GREEN}${BOLD}WHO AM I?${NC}\n"
echo "Dr. Ada Pipeline, Computational Biologist"
echo "Specialties: Metagenomics, HPC, workflow optimization"
echo "Lines of code written: Too many (most are Snakemake now)"
echo ""

echo -e "${GREEN}${BOLD}WHAT I CARE ABOUT:${NC}\n"

echo -e "${YELLOW}âš™ï¸  Pipeline Efficiency${NC}"
echo "   â€¢ Minimize I/O bottlenecks"
echo "   â€¢ Parallelize everything possible"
echo "   â€¢ Cache intermediate results"
echo "   â€¢ Fail fast with clear errors"
echo ""

echo -e "${YELLOW}ðŸ“Š Data Quality${NC}"
echo "   â€¢ GIGO: Garbage In, Garbage Out"
echo "   â€¢ QC at every step"
echo "   â€¢ Track contamination"
echo "   â€¢ Validate against known controls"
echo ""

echo -e "${YELLOW}ðŸ”„ Reproducibility${NC}"
echo "   â€¢ Version all software"
echo "   â€¢ Document parameters"
echo "   â€¢ Containerize workflows"
echo "   â€¢ Provide example datasets"
echo ""

echo -e "${GREEN}${BOLD}MY ADVICE FOR DANA PIPELINE:${NC}\n"

echo -e "${YELLOW}1. BEFORE YOU START${NC}"
echo "   âœ“ Check dependencies: ./status.sh"
echo "   âœ“ Test with small dataset first (100 reads)"
echo "   âœ“ Estimate resources (RAM, disk, time)"
echo "   âœ“ Set up logging directory"
echo "   âœ“ Plan checkpointing strategy"
echo ""

echo -e "${YELLOW}2. REAL-TIME PROCESSING TIPS${NC}"
echo "   âœ“ Use -K flag for Kraken (taxonomy is fast!)"
echo "   âœ“ Skip Prokka until post-expedition (it's slow)"
echo "   âœ“ Set --max-duration to avoid overruns"
echo "   âœ“ Monitor DuckDB size (it grows fast!)"
echo "   âœ“ Run dashboard in tmux/screen"
echo ""

echo -e "${YELLOW}3. MAG ASSEMBLY OPTIMIZATION${NC}"
echo "   âœ“ Flye: Use --meta mode, --threads to max"
echo "   âœ“ minimap2: -x map-ont for Nanopore"
echo "   âœ“ Binning: Run 3 tools overnight"
echo "   âœ“ CheckM2: MUCH faster than CheckM v1"
echo "   âœ“ Polish only high-quality bins (>70% complete)"
echo ""

echo -e "${YELLOW}4. COMPUTE RESOURCES${NC}"
echo "   ðŸ“¦ Real-time processing:"
echo "      â€¢ RAM: 32GB minimum, 64GB comfortable"
echo "      â€¢ CPU: 16+ cores (Kraken loves threads)"
echo "      â€¢ Disk: 500GB for typical expedition"
echo "      â€¢ Time: ~2-4 hours per barcode"
echo ""
echo "   ðŸ§¬ MAG assembly:"
echo "      â€¢ RAM: 128GB minimum, 256GB better"
echo "      â€¢ CPU: 32+ cores (Flye, MetaBAT parallel)"
echo "      â€¢ Disk: 1-2TB (assemblies are BIG)"
echo "      â€¢ Time: 1-3 days for complete pipeline"
echo ""

echo -e "${GREEN}${BOLD}COMMON ERRORS I'VE DEBUGGED 1000 TIMES:${NC}\n"

echo "ðŸ› \"Out of memory killed\""
echo "   Fix: Reduce threads, increase RAM, or split input"
echo ""
echo "ðŸ› \"Kraken database not found\""
echo "   Fix: Set KRAKEN_DB environment variable"
echo ""
echo "ðŸ› \"No such file or directory: assembly.fasta\""
echo "   Fix: Check previous step logs, assembly may have failed"
echo ""
echo "ðŸ› \"DAS_Tool: No bins passed quality filter\""
echo "   Fix: Lower --score_threshold, check bin quality"
echo ""
echo "ðŸ› \"Medaka: CUDA out of memory\""
echo "   Fix: Use CPU version or reduce batch size"
echo ""

echo -e "${GREEN}${BOLD}PERFORMANCE TUNING:${NC}\n"

echo -e "${YELLOW}âŒ DON'T DO THIS:${NC}"
echo "   â€¢ Process all barcodes sequentially (use parallel!)"
echo "   â€¢ Re-run entire pipeline after failure (use checkpoints!)"
echo "   â€¢ Store everything in one directory (organize!)"
echo "   â€¢ Run on login node (use compute nodes!)"
echo "   â€¢ Ignore errors (check logs!)"
echo ""

echo -e "${YELLOW}âœ… DO THIS:${NC}"
echo "   â€¢ Use GNU parallel for barcode processing"
echo "   â€¢ Check for existing outputs before rerunning"
echo "   â€¢ Separate by project/sample/date"
echo "   â€¢ Submit to SLURM/PBS queue"
echo "   â€¢ grep ERROR logs/ after each run"
echo ""

echo -e "${GREEN}${BOLD}QUALITY CONTROL CHECKLIST:${NC}\n"

echo "ðŸ“Š After Real-Time Processing:"
echo "   â–¡ Read count per sample >10K"
echo "   â–¡ Mean read length >2kb"
echo "   â–¡ Mean read quality >Q10"
echo "   â–¡ Kraken classified >50%"
echo "   â–¡ No single taxon >90% (likely contamination)"
echo "   â–¡ DuckDB queryable"
echo ""

echo "ðŸ§¬ After MAG Assembly:"
echo "   â–¡ Assembly N50 >10kb"
echo "   â–¡ Total contigs <100K"
echo "   â–¡ Recovered >20 MAGs"
echo "   â–¡ High-quality bins >5"
echo "   â–¡ Contamination <10% for all bins"
echo "   â–¡ Taxonomic assignment >80% of bins"
echo ""

echo -e "${GREEN}${BOLD}DEBUGGING WORKFLOW:${NC}\n"

echo "1. Check the logs!"
echo "   tail -100 logs/barcode01.log"
echo ""
echo "2. Verify inputs exist"
echo "   ls -lh input/barcode01/*.fastq.gz"
echo ""
echo "3. Test tool individually"
echo "   kraken2 --threads 4 --db \$KRAKEN_DB test.fq"
echo ""
echo "4. Check disk space"
echo "   df -h ."
echo ""
echo "5. Validate output format"
echo "   head -20 output/assembly.fasta"
echo ""

echo -e "${GREEN}${BOLD}ADVANCED TIPS:${NC}\n"

echo -e "${YELLOW}ðŸš€ Speed Hacks:${NC}"
echo "   â€¢ Use ramdisk (/dev/shm) for temp files"
echo "   â€¢ Compress with pigz (parallel gzip)"
echo "   â€¢ Use samtools view -@ for parallel BAM reading"
echo "   â€¢ Cache Kraken2 database in RAM (--memory-mapping)"
echo ""

echo -e "${YELLOW}ðŸ’¾ Storage Hacks:${NC}"
echo "   â€¢ Delete intermediate BAMs after depth calculation"
echo "   â€¢ Compress assemblies with gzip -9"
echo "   â€¢ Symlink raw reads instead of copying"
echo "   â€¢ Archive to tape after publication"
echo ""

echo -e "${YELLOW}ðŸ”§ Troubleshooting Hacks:${NC}"
echo "   â€¢ Run with -d (debug mode) to see commands"
echo "   â€¢ Use strace to debug file access issues"
echo "   â€¢ htop to monitor CPU/RAM in real-time"
echo "   â€¢ iostat -x 1 to find I/O bottlenecks"
echo ""

echo -e "${GREEN}${BOLD}RECOMMENDED READING:${NC}\n"

echo "ðŸ“š Metagenomic assembly:"
echo "   â€¢ Nurk et al. 2017 (metaSPAdes)"
echo "   â€¢ Kolmogorov et al. 2020 (metaFlye)"
echo ""
echo "ðŸ“š Binning methods:"
echo "   â€¢ Pan et al. 2023 (SemiBin2)"
echo "   â€¢ Kang et al. 2019 (MetaBAT2)"
echo "   â€¢ Sieber et al. 2018 (DAS_Tool)"
echo ""
echo "ðŸ“š Best practices:"
echo "   â€¢ Bowers et al. 2017 (MIMAG standards)"
echo "   â€¢ Nayfach et al. 2021 (CheckM2)"
echo ""

cat << "EOF"

     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚  ðŸ’»  "Bioinformatics is 90% data wrangling, â”‚
     â”‚       9% debugging, and 1% actual science.    â”‚
     â”‚       But that 1% changes the world."         â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

           Dr. Ada Pipeline, Bioinformatician

EOF

echo -e "${YELLOW}${BOLD}Need help? Ask me about:${NC}"
echo "â€¢ Pipeline optimization"
echo "â€¢ Resource requirements"
echo "â€¢ Error debugging"
echo "â€¢ Best practices"
echo ""
echo -e "${GREEN}ðŸ’» Code smarter, not harder! ðŸ’»${NC}\n"
