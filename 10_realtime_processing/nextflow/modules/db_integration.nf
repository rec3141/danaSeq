// DuckDB integration: load pipeline outputs into dana.duckdb
// Runs R scripts that expect a specific directory layout with publishDir outputs.
// Uses val(barcode_dir) since R scripts operate on the published output directory
// (host filesystem), not the Nextflow work directory.
// maxForks=1 to prevent concurrent DuckDB access

// Canonical 136 reverse-complement-collapsed tetranucleotide column names
// Generated by tetramer_freqs_esom.pl; fixed set used for tnfs.txt header
def TETRA_COLS = 'seqid\tAAAA\tAAAC\tAAAG\tAAAT\tAACA\tAACC\tAACG\tAACT\tAAGA\tAAGC\tAAGG\tAAGT\tAATA\tAATC\tAATG\tAATT\tACAA\tACAC\tACAG\tACAT\tACCA\tACCC\tACCG\tACCT\tACGA\tACGC\tACGG\tACGT\tACTA\tACTC\tACTG\tAGAA\tAGAC\tAGAG\tAGAT\tAGCA\tAGCC\tAGCG\tAGCT\tAGGA\tAGGC\tAGGG\tAGTA\tAGTC\tAGTG\tATAA\tATAC\tATAG\tATAT\tATCA\tATCC\tATCG\tATGA\tATGC\tATGG\tATTA\tATTC\tATTG\tCAAA\tCAAC\tCAAG\tCACA\tCACC\tCACG\tCAGA\tCAGC\tCAGG\tCATA\tCATC\tCATG\tCCAA\tCCAC\tCCAG\tCCCA\tCCCC\tCCCG\tCCGA\tCCGC\tCCGG\tCCTA\tCCTC\tCGAA\tCGAC\tCGAG\tCGCA\tCGCC\tCGCG\tCGGA\tCGGC\tCGTA\tCGTC\tCTAA\tCTAC\tCTAG\tCTCA\tCTCC\tCTGA\tCTGC\tCTTA\tCTTC\tGAAA\tGAAC\tGACA\tGACC\tGAGA\tGAGC\tGATA\tGATC\tGCAA\tGCAC\tGCCA\tGCCC\tGCGA\tGCGC\tGCTA\tGGAA\tGGAC\tGGCA\tGGCC\tGGGA\tGGTA\tGTAA\tGTAC\tGTCA\tGTGA\tGTTA\tTAAA\tTACA\tTAGA\tTATA\tTCAA\tTCCA\tTCGA\tTGAA\tTGCA\tTTAA'

process DB_INTEGRATION {
    tag "${barcode_dir}"
    label 'process_medium'
    conda "${projectDir}/conda-envs/dana-tools"
    maxForks 1
    executor 'local'

    input:
    val barcode_dir

    output:
    val barcode_dir

    script:
    """
    # R scripts do setwd(args[1]) then open dana.duckdb in that directory
    # They expect kraken/, prokka/, sketch/, tetra/ subdirectories
    # Patch hardcoded source("/work/apps/dana/log-db.r") to use danadir

    run_r_script() {
        local script="\$1"; shift
        local patched=\$(mktemp)
        sed -e 's|source("/work/apps/dana/log-db.r")|source("'${params.danadir}'/46_log_db.r")|' \
            -e 's|library(tidyverse)|library(stringr); library(dplyr); library(tidyr); library(tibble)|' \
            "\$script" > "\$patched"
        Rscript "\$patched" "\$@" || true
        rm -f "\$patched"
    }

    if [ -d "${barcode_dir}/kraken" ] && ls "${barcode_dir}"/kraken/*.tsv >/dev/null 2>&1; then
        run_r_script ${params.danadir}/40_kraken_db.r "${barcode_dir}"
        run_r_script ${params.danadir}/41_krakenreport_db.r "${barcode_dir}"
    fi

    if [ -d "${barcode_dir}/prokka" ]; then
        run_r_script ${params.danadir}/42_prokka_db.r "${barcode_dir}"
    fi

    if [ -d "${barcode_dir}/sketch" ] && ls "${barcode_dir}"/sketch/*.txt >/dev/null 2>&1; then
        run_r_script ${params.danadir}/43_sketch_db.r "${barcode_dir}"
    fi

    if [ -d "${barcode_dir}/tetra" ] && ls "${barcode_dir}"/tetra/*.lrn >/dev/null 2>&1; then
        # Generate tnfs.txt header if missing (required by 44_tetra_db.r)
        if [ ! -s "${barcode_dir}/tnfs.txt" ]; then
            printf '${TETRA_COLS}\\n' > "${barcode_dir}/tnfs.txt"
        fi
        run_r_script ${params.danadir}/44_tetra_db.r "${barcode_dir}"
    fi
    """
}

// Timer-driven DB sync for watch mode.
// Scans the output directory for all barcode subdirectories and runs R scripts
// on each. The R scripts are idempotent (they use import_log to track what's
// already been loaded), so repeated invocations on the same data are safe.

process DB_SYNC {
    tag "sync-${tick}"
    label 'process_medium'
    conda "${projectDir}/conda-envs/dana-tools"
    maxForks 1
    executor 'local'

    input:
    val tick           // from Channel.interval()
    val outdir         // absolute path to output directory
    val danadir        // path to R scripts directory

    output:
    val tick

    script:
    """
    run_r_script() {
        local script="\$1"; shift
        local patched=\$(mktemp)
        sed -e 's|source("/work/apps/dana/log-db.r")|source("'${danadir}'/46_log_db.r")|' \
            -e 's|library(tidyverse)|library(stringr); library(dplyr); library(tidyr); library(tibble)|' \
            "\$script" > "\$patched"
        Rscript "\$patched" "\$@" || true
        rm -f "\$patched"
    }

    echo "[INFO] DB_SYNC tick=${tick}: scanning ${outdir} for barcode directories"

    # Find all barcode directories (outdir/flowcell/barcodeNN)
    for barcode_dir in \$(find ${outdir} -mindepth 2 -maxdepth 2 -type d -name 'barcode*' | sort); do
        echo "[INFO] DB_SYNC: processing \${barcode_dir}"

        if [ -d "\${barcode_dir}/kraken" ] && ls "\${barcode_dir}"/kraken/*.tsv >/dev/null 2>&1; then
            run_r_script ${danadir}/40_kraken_db.r "\${barcode_dir}"
            run_r_script ${danadir}/41_krakenreport_db.r "\${barcode_dir}"
        fi

        if [ -d "\${barcode_dir}/prokka" ]; then
            run_r_script ${danadir}/42_prokka_db.r "\${barcode_dir}"
        fi

        if [ -d "\${barcode_dir}/sketch" ] && ls "\${barcode_dir}"/sketch/*.txt >/dev/null 2>&1; then
            run_r_script ${danadir}/43_sketch_db.r "\${barcode_dir}"
        fi

        if [ -d "\${barcode_dir}/tetra" ] && ls "\${barcode_dir}"/tetra/*.lrn >/dev/null 2>&1; then
            if [ ! -s "\${barcode_dir}/tnfs.txt" ]; then
                printf '${TETRA_COLS}\\n' > "\${barcode_dir}/tnfs.txt"
            fi
            run_r_script ${danadir}/44_tetra_db.r "\${barcode_dir}"
        fi
    done

    echo "[INFO] DB_SYNC tick=${tick}: complete"
    """
}
