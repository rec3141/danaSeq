// ============================================================================
// Dana Pipeline - Nextflow Configuration
// ============================================================================

// Default parameters (override via CLI: --param_name value)
params {
    // Required
    input           = null      // Input directory containing fastq_pass/

    // Output
    outdir          = "results"

    // Database paths (must be provided by user)
    kraken_db       = null              // Path to Kraken2 database directory (required if --run_kraken)
    danadir         = null              // Path to R scripts for DuckDB integration (required if --run_db_integration)

    // Kraken parse AWK script (shipped with pipeline)
    kraken_parse_awk = "${projectDir}/../30_kraken_parse.awk"

    // Pipeline control flags (match -K, -P, -S, -T CLI flags)
    run_kraken      = false
    run_prokka      = false
    run_sketch      = false
    run_tetra       = false
    hmm_databases   = null      // Comma-delimited HMM file paths
    run_db_integration = false

    // QC parameters
    min_readlen     = 1500
    keep_percent    = 80
    min_file_size   = 1000000   // 1MB minimum FASTQ size (matches MIN_SIZE="1M")
}

// ============================================================================
// Conda configuration
// ============================================================================
// Each process declares its own conda directive so Nextflow creates isolated
// environments per tool. Environments are cached in conda.cacheDir and reused
// across runs. First run builds envs; subsequent runs start instantly.

conda {
    enabled    = true
    cacheDir   = "${projectDir}/conda-envs"
    useMamba   = true   // Use mamba for faster env creation (falls back to conda)
    createTimeout = '60 min'
}

// ============================================================================
// Process resource labels
// ============================================================================

process {
    withLabel: 'process_low' {
        cpus   = 1
        memory = 2.GB
        time   = 1.h
    }
    withLabel: 'process_medium' {
        cpus   = 1
        memory = 4.GB
        time   = 2.h
    }
    withLabel: 'process_kraken' {
        cpus   = 1
        memory = 10.GB   // Adjust based on Kraken2 database size
        time   = 4.h
    }

    // Default error strategy: retry once, then ignore (match bash resilience)
    errorStrategy = { task.exitStatus in [1,143,137,104,134,139] ? 'retry' : 'ignore' }
    maxRetries    = 1
}

// ============================================================================
// Profiles
// ============================================================================

profiles {

    // Standard local execution - auto-detect resources
    standard {
        process.executor = 'local'
    }

    // Test profile - small files, reduced resources
    test {
        params {
            min_file_size = 1000        // 1KB minimum for test files
            min_readlen   = 500
            keep_percent  = 90
            outdir        = "test_results"
        }
    }

    // Shipboard production: 32 CPUs, 256GB RAM
    shipboard {
        process.executor = 'local'
        executor {
            cpus   = 32
            memory = '256 GB'
        }
        process {
            withLabel: 'process_kraken' {
                memory = 100.GB
            }
        }
    }

    // Use local tool installations instead of conda (legacy path-based mode)
    // Usage: -profile local_tools
    local_tools {
        conda.enabled = false
        params {
            bbmap       = "/work/apps/bbmap"
            filtlong    = "/work/apps/Filtlong/bin/filtlong"
            prokka_bin  = "/work/apps/prokka/bin/prokka"
            kraken2_bin = "/usr/bin/kraken2"
            hmmsearch   = "/usr/bin/hmmsearch"
            apps        = "/work/apps"
        }
    }
}

// ============================================================================
// Reports and tracing
// ============================================================================

timeline {
    enabled = true
    file    = "${params.outdir}/pipeline_info/timeline.html"
    overwrite = true
}

report {
    enabled = true
    file    = "${params.outdir}/pipeline_info/report.html"
    overwrite = true
}

trace {
    enabled = true
    file    = "${params.outdir}/pipeline_info/trace.txt"
    overwrite = true
    fields  = 'task_id,hash,native_id,process,tag,name,status,exit,submit,start,complete,duration,realtime,%cpu,%mem,rss,peak_rss'
}

dag {
    enabled = true
    file    = "${params.outdir}/pipeline_info/dag.html"
    overwrite = true
}

// ============================================================================
// Manifest
// ============================================================================

manifest {
    name            = 'dana-realtime'
    author          = 'Dana Pipeline'
    description     = 'Real-time Nanopore metagenomic processing pipeline'
    mainScript      = 'main.nf'
    nextflowVersion = '>=23.04.0'
    version         = '1.0.0'
}

// ============================================================================
// Validation
// ============================================================================

// Check required params on startup
def checkParams() {
    if (!params.input) {
        exit 1, "ERROR: --input is required. Provide path to directory containing fastq_pass/"
    }
    if (params.run_kraken && !params.kraken_db) {
        exit 1, "ERROR: --kraken_db is required when using --run_kraken. Provide path to Kraken2 database directory."
    }
    if (params.run_db_integration && !params.danadir) {
        exit 1, "ERROR: --danadir is required when using --run_db_integration. Provide path to R scripts directory."
    }
}
checkParams()
