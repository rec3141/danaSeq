// ============================================================================
// Dana Pipeline - Nextflow Configuration
// ============================================================================

// Default parameters (override via CLI: --param_name value)
params {
    // Help
    help            = false

    // Required
    input           = null      // Input directory containing fastq_pass/

    // Output
    outdir          = "results"

    // Database paths (must be provided by user)
    kraken_db       = null              // Path to Kraken2 database directory (required if --run_kraken)
    danadir         = null              // Path to R scripts for DuckDB integration (required if --run_db_integration)

    // Kraken parse AWK script (shipped with pipeline)
    kraken_parse_awk = "${projectDir}/bin/30_kraken_parse.awk"

    // Pipeline control flags (match -K, -P, -S, -T CLI flags)
    run_kraken      = false
    run_prokka      = false         // (deprecated) use --annotator prokka
    run_bakta       = false         // (deprecated) use --annotator bakta
    annotator       = null          // Preferred: 'prokka', 'bakta', or 'none'. Overrides run_prokka/run_bakta
    bakta_db        = null          // Path to Bakta database (required when using Bakta)
    run_sketch      = false
    run_tetra       = false
    hmm_databases   = null      // Comma-delimited HMM file paths
    run_db_integration = false

    // Watch mode for live sequencing
    watch           = false     // Enable watch mode for live sequencing runs
    db_sync_minutes = 10        // DB sync interval in watch mode (minutes)
    watch_glob      = '*/fastq_pass/barcode*/*.fastq.gz'  // Glob for watchPath (no ** â€” Java WatchService limitation)

    // Post-DB cleanup: compress/delete source files after DuckDB import
    cleanup         = false     // Enable post-DB cleanup of source files

    // QC parameters
    min_readlen     = 1500
    keep_percent    = 80
    min_file_size   = 1000000   // 1MB minimum FASTQ size (matches MIN_SIZE="1M")
}

// ============================================================================
// Conda configuration
// ============================================================================
// Each process declares its own conda directive so Nextflow creates isolated
// environments per tool. Environments are cached in conda.cacheDir and reused
// across runs. First run builds envs; subsequent runs start instantly.

conda {
    enabled    = true
    cacheDir   = "${projectDir}/conda-envs"
    useMamba   = true   // Use mamba for faster env creation (falls back to conda)
    createTimeout = '60 min'
}

// ============================================================================
// Process resource labels
// ============================================================================

process {
    fair = true   // Distribute resources evenly across process types

    withLabel: 'process_low' {
        cpus   = 1
        memory = 2.GB
        time   = 1.h
    }
    withLabel: 'process_medium' {
        cpus   = 1
        memory = 4.GB
        time   = 2.h
    }
    withLabel: 'process_kraken' {
        cpus   = 1
        memory = 10.GB   // Adjust based on Kraken2 database size
        time   = 4.h
    }

    // Default error strategy: retry once, then ignore (match bash resilience)
    errorStrategy = { task.exitStatus in [1,143,137,104,134,139] ? 'retry' : 'ignore' }
    maxRetries    = 1
}

// ============================================================================
// Profiles
// ============================================================================

profiles {

    // Standard local execution - auto-detect resources
    standard {
        process.executor = 'local'
    }

    // Test profile - small files, reduced resources
    test {
        params {
            min_file_size = 1000        // 1KB minimum for test files
            min_readlen   = 500
            keep_percent  = 90
            outdir        = "test_results"
        }
    }

    // Shipboard production: 32 CPUs, 256GB RAM
    shipboard {
        process.executor = 'local'
        executor {
            cpus   = 32
            memory = '256 GB'
        }
        process {
            withLabel: 'process_kraken' {
                memory = 100.GB
            }
        }
    }

    // Use local tool installations instead of conda (legacy path-based mode)
    // Usage: -profile local_tools
    local_tools {
        conda.enabled = false
        params {
            bbmap       = "/work/apps/bbmap"
            filtlong    = "/work/apps/Filtlong/bin/filtlong"
            prokka_bin  = "/work/apps/prokka/bin/prokka"
            kraken2_bin = "/usr/bin/kraken2"
            hmmsearch   = "/usr/bin/hmmsearch"
            apps        = "/work/apps"
        }
    }
}

// ============================================================================
// Reports and tracing
// ============================================================================

timeline {
    enabled = true
    file    = "${params.outdir}/pipeline_info/timeline.html"
    overwrite = true
}

report {
    enabled = true
    file    = "${params.outdir}/pipeline_info/report.html"
    overwrite = true
}

trace {
    enabled = true
    file    = "${params.outdir}/pipeline_info/trace.txt"
    overwrite = true
    fields  = 'task_id,hash,native_id,process,tag,name,status,exit,submit,start,complete,duration,realtime,%cpu,%mem,rss,peak_rss'
}

dag {
    enabled = true
    file    = "${params.outdir}/pipeline_info/dag.html"
    overwrite = true
}

// ============================================================================
// Manifest
// ============================================================================

manifest {
    name            = 'dana-realtime'
    author          = 'Dana Pipeline'
    description     = 'Real-time Nanopore metagenomic processing pipeline'
    mainScript      = 'main.nf'
    nextflowVersion = '>=23.04.0'
    version         = '1.0.0'
}

// ============================================================================
// Validation
// ============================================================================

// Parameter validation is done in main.nf (DSL2 requires it there)
